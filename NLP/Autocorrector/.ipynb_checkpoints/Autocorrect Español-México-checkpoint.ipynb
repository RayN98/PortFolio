{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed4e15b",
   "metadata": {},
   "source": [
    "# Autocorrector Español-México"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4539c0",
   "metadata": {},
   "source": [
    "The following notebook aims to create a simple Spanish-México autocorrect that covers each step of the process, from the compilation of the training corpus to its final test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2af256",
   "metadata": {},
   "source": [
    "## 1.- Gathering wikipedia corpus data\n",
    "In this section, we will be using gensim python library to build a corpus from the set of Spanish Wikipedia articles, which is freely to use, and tqdm to monitor the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97eb1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring certain warnings caused by incompatibility of some libraries versions with gensim\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "from gensim.corpora import WikiCorpus\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc28622",
   "metadata": {},
   "source": [
    "The following function opens the wiki.xml.bz2 file where the articles are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8dfd37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(in_f, out_f):\n",
    "    output = open(out_f, 'w', encoding=\"utf8\")\n",
    "    wiki = WikiCorpus(in_f)\n",
    "    for text in tqdm(wiki.get_texts()):\n",
    "        output.write(bytes(' '.join(text), 'utf-8').decode('utf-8') + '\\n')\n",
    "    output.close()\n",
    "    print('Processing complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1243536",
   "metadata": {},
   "source": [
    "Calling the function with the path of the wiki file and the new document path will begin the process of making the corpus (Uncomment the row in the below section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124fe3fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1591007it [1:05:32, 404.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "wiki_path = \"C:/Python Projects/GitHub/Portfolio/NLP (Natural Languaje Processing)/Autocorrector/eswiki-latest-pages-articles.xml.bz2\"\n",
    "corpus_path = \"C:/Python Projects/GitHub/Portfolio/NLP (Natural Languaje Processing)/Autocorrector/wiki_es.txt\"\n",
    "\n",
    "# make_corpus(wiki_path, corpus_path)"
   ]
  },
  {
   "attachments": {
    "tqdm_2.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "id": "e5477c74",
   "metadata": {},
   "source": [
    "![tqdm_2.jpg](attachment:tqdm_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15aa0ad",
   "metadata": {},
   "source": [
    "## 2.- Checking wikipedia corpus data\n",
    "The following section is going to be used to check the corpus lines opening the file we just former created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = open(out_f, 'r', encoding='utf8')\n",
    "\n",
    "# Number of lines to check in the corpus\n",
    "lines_check = 1\n",
    "\n",
    "for lines in range(lines_check):\n",
    "    text = corpus_file.readline()\n",
    "    print(text)\n",
    "\n",
    "corpus_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c2f606",
   "metadata": {},
   "source": [
    "## 3.- Cleaning the corpus\n",
    "Spanish language has a lot of variants depending on the region, in this specific project we are interested in México. Furthermore, we will select only the words that contain characters used in this region (i.e; a, b, c, d, e, f, g, h, i, j, k, l, m, n, ñ, o, p, q, r, s, t, u, v, w, x, y, z, á, é, í, ó, ú, ü), which is the vocabulary.\n",
    "\n",
    "Dividing the documents into words, and using the RegEx library flags will do the work. Every text cleaned will be appended into a new document called wiki_clean_es.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ec2594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1591007/1591007 [1:34:28<00:00, 280.70it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_row(w):\n",
    "    text_divided = w.split(' ')\n",
    "    clean_text = []\n",
    "    # Create a dictionary to convert the vocabulary (characters) to integers\n",
    "    vocab = 'abcdefghijklmnñopqrstuvwxyzáéíóúü'\n",
    "    for word in text_divided:\n",
    "        x = [0 for word_spell in word if not re.search(word_spell, vocab)]\n",
    "        if len(x) == 0:\n",
    "            clean_text.append(word)\n",
    "    return \" \".join(clean_text)\n",
    "\n",
    "def clean_corpus(f_in, f_out):\n",
    "    clean_file = open(f_out, 'a', encoding='utf8')\n",
    "    with open(f_in, 'r', encoding='utf-8') as f:\n",
    "        text = f.readlines()\n",
    "    for lines in tqdm(text):\n",
    "        clean_file.write(f\"{clean_row(lines)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d336869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_path = \"C:/Python Projects/GitHub/Portfolio/NLP (Natural Languaje Processing)/Autocorrector/wiki_clean_es.txt\"\n",
    "\n",
    "# clean_corpus(corpus_path, clean_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea433d3",
   "metadata": {},
   "source": [
    "## 4.- Creating the text vocabulary and obtain probabilities\n",
    "As stated before, we will calculate the probability that each word is in a sentence to serve as the basis for the autocorrect.\n",
    "\n",
    "In the previous section we cleaned the words to the only ones that contain valid characters in Mexico. But we need to be sure that those words are meaningful. To be solve the problem, we will use the RAE (Real Academia Española) dictionary, also cleaning it to contain only words valid in México."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a51c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(f_in, f_path, f_rae):\n",
    "    # Load RAE Dictionary\n",
    "    with open(f_rae, 'r', encoding='utf-8') as g:\n",
    "        # Split RAE bDictionary into words\n",
    "        rae_dict = g.read().split('\\n')\n",
    "        letters = 'abcdefghijklmnñopqrstuvwxyzáéíóúü'\n",
    "        clean_rae_dict = []\n",
    "        # Clean RAE Dictionary\n",
    "        for word in rae_dict:\n",
    "            word = re.sub('\\d+', '', word)\n",
    "            word = re.sub('[.()-]', '', word)\n",
    "            x = [0 for word_spell in word if not re.search(word_spell, letters)]\n",
    "            if len(x) == 0:\n",
    "                clean_rae_dict.append(word)\n",
    "            else:\n",
    "                continue\n",
    "        # Create the initial vocabulary\n",
    "        g.close()\n",
    "        words_freq = {}\n",
    "        for word in clean_rae_dict:\n",
    "            words_freq[word] = 1\n",
    "\n",
    "    # Load corpus file\n",
    "    with open(f_in, 'r', encoding='utf-8') as f:\n",
    "        text = f.readlines()\n",
    "\n",
    "    # Analyze the file\n",
    "    for lines in tqdm(text):\n",
    "        # Find all unique words in the text\n",
    "        words = re.findall('\\w+', lines)\n",
    "        # Compute the frequency of every word\n",
    "        line_word_freq = Counter(words)\n",
    "        # Append new words to dictionary\n",
    "        for word in line_word_freq:\n",
    "            if word in words_freq:\n",
    "                words_freq[word] += line_word_freq[word]\n",
    "    f.close()\n",
    "\n",
    "    # Save the original words_freq_dictionary\n",
    "    with open(f\"{f_path}/raw_words_freq.pkl\", 'wb') as g:\n",
    "        pickle.dump(words_freq, g)\n",
    "        g.close()\n",
    "        \n",
    "    # Number of words used for the final dictionary\n",
    "    dictionary_n_words = 250000\n",
    "    n_words(dictionary_n_words, words_freq, f_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b733cd4",
   "metadata": {},
   "source": [
    "The following function restricts the vocabulary length to the desired number, in this case it will be set to 250,000 words. It saves 3 instances, the probabilities of every word to be in the text, the vocabulary, and the total number of aparitions of the word in the text corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a7ce1",
   "metadata": {},
   "source": [
    "## 5.- Creating the text vocabulary and obtain probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca11606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_words(n, words_freq, f_path):\n",
    "    words_freq = Counter(words_freq)\n",
    "    # Find the n most common words\n",
    "    word_most_common = words_freq.most_common()[:n]\n",
    "\n",
    "    # Create a new dictionary with the words\n",
    "    word_freq_dict = {}\n",
    "    for word in word_most_common:\n",
    "        word_freq_dict[word[0]] = word[1]\n",
    "    # Create final vocabulary\n",
    "    vocab = set(word for word in word_freq_dict)\n",
    "    Total = sum(word_freq_dict.values())\n",
    "\n",
    "    print(word_most_common)\n",
    "\n",
    "    # Probabilities of every word\n",
    "    probs = {}\n",
    "    for k in word_freq_dict.keys():\n",
    "        probs[k] = word_freq_dict[k]/Total\n",
    "\n",
    "    # Save the probabilities of every word\n",
    "    with open(f\"{f_path}/probs_es.pkl\", 'wb') as f1:\n",
    "        pickle.dump(probs, f1)\n",
    "        f1.close()\n",
    "    #Save the vocabulary\n",
    "    with open(f\"{f_path}/vocab_es.pkl\", 'wb') as f2:\n",
    "        pickle.dump(vocab, f2)\n",
    "        f2.close()\n",
    "    # Save the dictionary of frequent words\n",
    "    with open(f\"{f_path}/word_freq_es.pkl\", 'wb') as f3:\n",
    "        pickle.dump(word_freq_dict, f3)\n",
    "        f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = \"C:/Python Projects/GitHub/Portfolio/NLP (Natural Languaje Processing)/Autocorrector\"\n",
    "rae_path = \"C:/Python Projects/GitHub/Portfolio/NLP (Natural Languaje Processing)/Autocorrector/RAE_dic.txt\"\n",
    "\n",
    "get_vocab(clean_path, files_path, rae_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0627a2",
   "metadata": {},
   "source": [
    "## 6.- Generating possible candidates of the correct word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf71f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_autocorrect(sentence):\n",
    "    new_sentence = sentence.split(' ')\n",
    "    sentence_clean = []\n",
    "    if len(new_sentence) > 0:\n",
    "        for word in new_sentence:\n",
    "            if word == '':\n",
    "                continue\n",
    "            predictions = check(word)\n",
    "            sentence_clean.append(predictions)\n",
    "        print(' '.join(sentence_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58571521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(word):\n",
    "    probs_path = \"C:/Python Projects/GitHub/Portfolio/NLP/Autocorrector/probs_es.pkl\"\n",
    "    vocab_path = \"C:/Python Projects/GitHub/Portfolio/NLP/Autocorrector/vocab_es.pkl\"\n",
    "    probs = pickle.load(open(probs_path, 'rb'))\n",
    "    vocab = pickle.load(open(vocab_path, 'rb'))\n",
    "    if word in vocab:\n",
    "        return (word)\n",
    "    candidates = l_one_edits(word) or l_two_edits(word) or [word]\n",
    "    valid_candidates = [w for w in candidates if w in vocab]\n",
    "    if len(valid_candidates) > 0:\n",
    "        return sorted([(c, probs[c]) for c in valid_candidates], key=lambda tup: tup[1], reverse=True)[0][0]\n",
    "    else:\n",
    "        return (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29a14e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_one_edits(word):\n",
    "    letters = 'abcdefghijklmnñopqrstuvwxyzáéíóúü'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [l + r[1:] for l, r in splits if r]\n",
    "    swaps = [l + r[1] + r[0] + r[2:] for l, r in splits if len(r) > 1]\n",
    "    replaces = [l + c + r[1:] for l, r in splits if r for c in letters]\n",
    "    inserts = [l + c + r for l, r in splits for c in letters]\n",
    "    return set(deletes + swaps + replaces + inserts)\n",
    "\n",
    "def l_two_edits(word):\n",
    "    return set(e2 for e1 in l_one_edits(word) for e2 in l_one_edits(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1643be",
   "metadata": {},
   "source": [
    "## 7.- Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b3b00",
   "metadata": {},
   "source": [
    "Finally, we are able to try our model!!\n",
    "\n",
    "We will validate the function of this autocorrect calling the function with the desired string, in this example we will verify the following sentence:\n",
    "\n",
    "hoal munbo oy es un beun dia  --> hola mundo hoy es un buen día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01a7246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola mundo hoy es un buen día\n"
     ]
    }
   ],
   "source": [
    "sentence_autocorrect('hoal munbo oy es un beun día')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf5519",
   "metadata": {},
   "source": [
    "Which corresponds to the correct spelling of the sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
